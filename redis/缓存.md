# 前言

Redis的分片技术我确实掌握的不行，对于我而言只需要知道哈希槽（哈希槽中有16384(即2的14次方）个哈希槽，每个key通过CRC16校验后对16383取模来决定放置哪个槽）的概念。如果想要深入了解的可以自行百度或者https://www.pdai.tech/md/db/nosql-redis/db-redis-x-cluster.html#redis-%E9%9B%86%E7%BE%A4%E7%9A%84%E8%AE%BE%E8%AE%A1%E7%9B%AE%E6%A0%87。本篇主要关注在Redis的缓存问题上。

# Redis缓存

在高并发的业务下，数据库大多数情况下是用户并发访问的最薄弱的环节。所以我们需要用Redis做一个缓冲操作，不让用户直接去访问数据库，让请求先去访问Redis。这样可以大大缓解Redis的压力。

当缓存库出现的时候，必须考虑的问题：

- 缓存穿透
- 缓存击穿
- 缓存雪崩
- 缓存污染
- 缓存和数据库的一致性



## 缓存穿透

**定义：**

​	缓存穿透是指在**缓存和数据库中都没有的数据** ，而用户不断的发起请求去获取。由于缓存是不命中时被动写的，并且处于容错的考虑，如果数据库没有查到数据是不会写入缓存的，这将导致每次访问不存在的数据都要直接访问数据数据库，失去缓存的意义。

在流量大时，可能DB就挂掉了，要是有人利用不存在的key频繁攻击我们的应用，这就是漏洞。

如发起为id为“-1”的数据或id为特别大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大。

**解决：**

	1. 接口层增加校验，比如id<=0的直接拦截
 	2. 从缓存取不到的数据，在数据库中也没有取到，可以将key-value键值对写成key-null，缓存有效时间设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击
 	3. 布隆过滤器，这个放在最后会单独开一篇讲。bloomfilter就类似于一个hash set，用于快速判某个元素是否存在于集合中，其典型的应用场景就是快速判断一个key是否存在于某容器，不存在就直接返回。布隆过滤器的关键就在于hash算法和容器大小。



## 缓存击穿

**定义：**

​	缓存击穿是指**缓存中没有数据但是数据库中有数据**（一般是缓存到期），这时由于并发用户特别多，同时读取缓存没有读取到，又同时取读取数据库的数据，导致数据库压力过大。

**解决：**

	1. 设置热点数据永不过期
 	2. 接口限流与熔断，降级。重要的接口一定要做好限流策略，防止用户恶意刷接口，同时要降级准备，当接口中的某些 服务  不可用时候，进行熔断，失败快速返回机制。
 	3. 加互斥锁



## 缓存雪崩

**定义：**

​	缓存雪崩是指**缓存中大量缓存数据同时到过期时间，同时失效，而查询数据量巨大，引起数据库压力增大甚至down机**。与缓存击穿不同的是，缓存击穿是指并发的查同一条数据，而缓存雪崩是不同的数据同时到期。

**解决：**

1. 缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。
2. 如果缓存数据库是分布式部署，将热点数据均匀分布在不同的缓存数据库中。
3. 设置热点数据永远不过期。

## 缓存污染

**定义：**

​	缓存污染是指缓存中一些数据只会被访问一次或者几次的数据，被访问完后再也不会被访问到，但这部分的数据依然留在缓存中，消耗缓存空间。

缓存污染会随着数据的持续增加而逐渐显露，随着服务的不断运行，缓存中会存在大量的永远不会再次被访问的数据。缓存空间是有限的，如果缓存空间满了，再往缓存里写数据时就会有额外开销，影响Redis性能。这部分额外开销主要是指写的时候判断淘汰策略，根据淘汰策略去选择要淘汰的数据，然后进行删除操作。

### 缓存淘汰策略

主要是八大策略：

- 不淘汰
  - noeviction （v4.0后默认的）

- 对设置了过期时间的数据中进行淘汰

  - 随机：volatile-random

  - ttl：volatile-ttl

  - lru：volatile-lru

  - lfu：volatile-lfu

- 全部数据进行淘汰
  - 随机：allkeys-random
  - lru：allkeys-lru
  - lfu：allkeys-lfu



1. **noeviction**

   该策略是Redis的默认策略。在这种策略下，一旦缓存被写满了，再有写请求来时，Redis 不再提供服务，而是直接返回错误。这种策略不会淘汰数据，所以无法解决缓存污染问题。一般生产环境不建议使用。

​	2. **volatile-random**

​		这个算法比较简单，在设置了过期时间的键值对中，进行随机删除。因为是随机删除，所以依然会有污染情况的产生。

​	3. **volatile-ttl**

​		这种算法判断淘汰数据时参考的指标比随机删除时多进行一步过期时间的排序。Redis在筛选需删除的数据时，越早过期的数据越优先被选择。

接下来比较两个重要的算法就是LRU算法和LFU算法。

**LRU算法：**

LRU 算法的全称是 Least Recently Used，按照最近最少使用的原则来筛选数据。这种模式下会使用 LRU 算法筛选设置了过期时间的键值对。

**LFU 算法**：

LFU 缓存策略是在 LRU 策略基础上，为每个数据增加了一个计数器，来统计这个数据的访问次数。当使用 LFU 策略筛选淘汰数据时，首先会根据数据的访问次数进行筛选，把访问次数最低的数据淘汰出缓存。如果两个数据的访问次数相同，LFU 策略再比较这两个数据的访问时效性，把距离上一次访问时间更久的数据淘汰出缓存。 Redis的LFU算法实现:



## 数据库和缓存一致性

使用redis做一个缓冲操作，让请求先访问到redis，而不是直接访问MySQL等数据库。

读取缓存步骤一般没有什么问题，但是一旦涉及到数据更新：数据库和缓存更新，就容易出现缓存(Redis)和数据库（MySQL）间的数据一致性问题。

**不管是先写MySQL数据库，再删除Redis缓存；还是先删除缓存，再写库，都有可能出现数据不一致的情况**。举一个例子：

1.如果删除了缓存Redis，还没有来得及写库MySQL，另一个线程就来读取，发现缓存为空，则去数据库中读取数据写入缓存，此时缓存中为脏数据。

2.如果先写了库，在删除缓存前，写库的线程宕机了，没有删除掉缓存，则也会出现数据不一致情况。

因为写和读是并发的，没法保证顺序,就会出现缓存和数据库的数据不一致的问题。

> 更新缓存的的Design Pattern有四种：Cache aside, Read through, Write through, Write behind caching; 我强烈建议你看看这篇，左耳朵耗子的文章：[缓存更新的套路](https://coolshell.cn/articles/17416.html)

**节选最最常用的Cache Aside Pattern, 总结来说就是**

- **读的时候**，先读缓存，如果没有缓存，就读数据库，然后取出数据放入缓存并返回。
- **写的时候**，先更新数据库，再删除缓存

**具体逻辑：**

- **失效：** 程序先从缓存中读数据，如果没有，则从数据库中获取数据，成功后放入缓存中。
- **命中：** 程序从缓存中取到数据，成功后返回。
- **更新：** 先把数据更新到数据库中，成功后，再让缓存失效。

那这个是否能解决问题？

一个是查询操作，一个是更新操作的并发，首先，没有了删除cache数据的操作了，而是先更新了数据库中的数据，此时，缓存依然有效，所以，并发的查询操作拿的是没有更新的数据，但是，更新操作马上让缓存的失效了，后续的查询操作再把数据从数据库中拉出来。而不会像文章开头的那个逻辑产生的问题，后续的查询操作一直都在取老的数据。

但这依然会有并发问题，比如，一个是读操作，但是没有命中缓存，然后就到数据库中取数据，此时来了一个写操作，写完数据库后，让缓存失效，然后，之前的那个读操作再把老的数据放进去，所以，会造成脏数据。

当然还有别的方案，可以去左耳朵耗子的文章：[缓存更新的套路](https://coolshell.cn/articles/17416.html) 查看更多。



## 布隆过滤器

想要尽量避免缓存穿透，一个办法就是对数据进行**预校验**，在对Redis和数据库进行操作前，**先检查数据是否存在，如果不存在就直接返回。**如果我们想要查询一个元素是否存在，要保证查询效率，可以选择HashSet，但是如果有10亿个数据，都用HashSet进行存储，**内存肯定是无法容纳的**。这时就需要布隆过滤器了

布隆过滤器实际上是由一个很长的二进制向量(bit数组)和一系列随机的映射函数(hash)。布隆过滤器可以用于检索一个元素是否在一个集合中

因为是基于**位数组和hash函数**的，所以它的**优点**是**空间效率和查询**时间都远远超过一般的算法。但**缺点**也很明显，那就是有一定的误识别率和删除困难。但是可以通过增加位数组的大小和增加hash函数个数来**降低**误识别率（**只能降低，没法避免**）这里的误识别率是指Bloom Filter报告某一元素存在于某集合中，但是实际上该元素并不在集合中，但是如果不在这个集合中，则Bloom Filter则一定不会报告在集合中。主要原因还是因为哈希碰撞。

算法：

1. 首先需要k个hash函数，每个函数可以把key散列成为1个整数
2. 初始化时，需要一个长度为n比特的数组，每个比特位初始化为0
3. 某个key加入集合时，用k个hash函数计算出k个散列值，并把数组中对应的比特位置为1
4. 判断某个key是否在集合时，用k个hash函数计算出k个散列值，并查询数组中对应的比特位，如果所有的比特位都是1，认为在集合中。









## 参考文章

https://www.pdai.tech/md/db/nosql-redis/db-redis-x-cache.html

https://coolshell.cn/articles/17416.html

https://www.cnblogs.com/rjzheng/p/9041659.html

https://my.oschina.net/jiagouzhan/blog/2990423

https://blog.csdn.net/qq_38261137/article/details/106949963

https://www.cnblogs.com/liyulong1982/p/6013002.html